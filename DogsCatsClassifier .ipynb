{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Dogs v/s Cats Classification"},{"metadata":{},"cell_type":"markdown","source":"This is a classification problem which consists of 25000 images of dogs and cats in jpeg format. Our task is to correctly classify them as dogs and cats using convolutional neural networks."},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{},"cell_type":"markdown","source":"We will be using keras framework for implementing our model"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import keras\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom sklearn.metrics import classification_report\nimport cv2\nfrom tqdm import tqdm","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nimage_ids = os.listdir('../input/train/train/')","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the data consists of images named as \"dog.1.jpg\", so we will store the image information in the x_train list and the category into y_train list."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = []\ny_train = []\nfor i in tqdm(image_ids):\n    category = i.split(\".\")[0]\n    if category == \"dog\":\n        y_train.append(1)\n    else:\n        y_train.append(0)\n        \n    img_arr = cv2.imread(\"../input/train/train/\"+i, cv2.IMREAD_GRAYSCALE)\n    img_arr = cv2.resize(img_arr, dsize=(128, 128))\n    x_train.append(img_arr)","execution_count":3,"outputs":[{"output_type":"stream","text":"100%|██████████| 25000/25000 [00:43<00:00, 580.42it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = np.array(x_train)\nx_train.shape","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"(25000, 128, 128)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = x_train/255\nx_train = x_train.reshape(-1, 128, 128, 1)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nf = open(\"x_train.pickle\", \"wb\")\npickle.dump(x_train, f)\nf.close()\nf = open(\"y_train.pickle\", \"wb\")\npickle.dump(y_train,f)\nf.close()","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(4,(3,3),strides=1, padding='valid', activation = 'relu', input_shape = x_train.shape[1:]))\nmodel.add(MaxPooling2D(pool_size = (2,2), strides=2))\n\nmodel.add(Conv2D(16,(3,3), activation = 'relu', strides=1, padding=\"valid\"))\nmodel.add(MaxPooling2D(pool_size = (2,2), strides=2))\n\nmodel.add(Conv2D(32, (3,3), activation=\"relu\", strides=1, padding=\"valid\"))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=2))\n\nmodel.add(Conv2D(64, (3,3), activation=\"relu\", strides=1, padding=\"valid\"))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=2))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation=\"relu\"))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(64, activation='sigmoid'))\n\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":8,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=\"adam\",\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":10,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 126, 126, 4)       40        \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 63, 63, 4)         0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 61, 61, 16)        592       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 30, 30, 16)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 28, 28, 32)        4640      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 12, 12, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 2304)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               1180160   \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               65664     \n_________________________________________________________________\ndense_3 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_4 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 1,277,913\nTrainable params: 1,277,913\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, epochs=7, batch_size=32, validation_split=0.2)","execution_count":11,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 20000 samples, validate on 5000 samples\nEpoch 1/7\n20000/20000 [==============================] - 12s 579us/step - loss: 0.6251 - acc: 0.6343 - val_loss: 0.5695 - val_acc: 0.7020\nEpoch 2/7\n20000/20000 [==============================] - 5s 275us/step - loss: 0.4941 - acc: 0.7597 - val_loss: 0.4699 - val_acc: 0.7782\nEpoch 3/7\n20000/20000 [==============================] - 6s 277us/step - loss: 0.4279 - acc: 0.8001 - val_loss: 0.4377 - val_acc: 0.7966\nEpoch 4/7\n20000/20000 [==============================] - 6s 276us/step - loss: 0.3714 - acc: 0.8362 - val_loss: 0.4112 - val_acc: 0.8056\nEpoch 5/7\n20000/20000 [==============================] - 6s 278us/step - loss: 0.3120 - acc: 0.8662 - val_loss: 0.4301 - val_acc: 0.8090\nEpoch 6/7\n20000/20000 [==============================] - 6s 277us/step - loss: 0.2540 - acc: 0.8928 - val_loss: 0.4592 - val_acc: 0.8064\nEpoch 7/7\n20000/20000 [==============================] - 6s 277us/step - loss: 0.1822 - acc: 0.9284 - val_loss: 0.4657 - val_acc: 0.8206\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"<keras.callbacks.History at 0x7f03617a4630>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = open(\"model.pickle\", \"wb\")\npickle.dump(model, f)\nf.close()","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = []\ntest_files = os.listdir(\"../input/test1/test1/\")\nfor i in tqdm(test_files):    \n    img_arr = cv2.imread(\"../input/test1/test1/\"+i, cv2.IMREAD_GRAYSCALE)\n    img_arr = cv2.resize(img_arr, dsize=(128, 128))\n    x_test.append(img_arr)","execution_count":13,"outputs":[{"output_type":"stream","text":"100%|██████████| 12500/12500 [00:21<00:00, 588.67it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = np.array(x_test)/255\nx_test = x_test.reshape(-1, 128, 128, 1)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.shape","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"(12500, 128, 128, 1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(x_test)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nfor i in predictions:\n    if(i>0.5):\n        results.append(1)\n    else:\n        results.append(0)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"id\":[i+1 for i in range(12500)], \n                   \"lable\" : [p for p in results]})","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(\"submission.csv\",index=False)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}