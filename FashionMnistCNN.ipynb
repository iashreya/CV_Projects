{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_mnist_ann.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR4eGEDduO_9",
        "colab_type": "text"
      },
      "source": [
        "# Classification of fashion items based on images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBVlDdHnt8sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, Flatten\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9m0Bd-puD6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMMhWqGCua6v",
        "colab_type": "text"
      },
      "source": [
        "## Analyzing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxw9WG1xuLOI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "60a2b460-a7e7-4bcb-8cde-57c10dc8d263"
      },
      "source": [
        "print(\"Length of training set = \", len(x_train))\n",
        "print(\"Length of test set = \", len(x_test))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of training set =  60000\n",
            "Length of test set =  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhUNEwi8vE4z",
        "colab_type": "text"
      },
      "source": [
        "**The dataset consists of images with their labels indicating the type of fashion item**<br>\n",
        ">\n",
        ">These are the following labels alongwith their description : <br>\n",
        ">\n",
        ">**Label\tDescription**<br>\n",
        ">0\tT-shirt/top<br>\n",
        ">1\tTrouser<br>\n",
        ">2\tPullover<br>\n",
        ">3\tDress<br>\n",
        ">4\tCoat<br>\n",
        ">5\tSandal<br>\n",
        ">6\tShirt<br>\n",
        ">7\tSneaker<br>\n",
        ">8\tBag<br>\n",
        ">9\tAnkle boot<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjvLSvIUwiyC",
        "colab_type": "text"
      },
      "source": [
        "**Now, let's have a look at one of the images to get a better idea of our dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFB52tq0uo_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "68608960-f6d3-4824-ebd3-0e3f2f8bbcc2"
      },
      "source": [
        "f, ax = plt.subplots(1, figsize=(2,2))\n",
        "ax.imshow(x_train[5], cmap=\"Greens\")\n",
        "print(\"Label = \", y_train[5])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label =  2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAACPCAYAAAARM4LLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADbBJREFUeJztnWlsXNUVx/9nVttjO068JLbjJG5w\nSYG2LBZLQQWaJk1SCZCgLJVQVdFWrUDqgirWfilqVaS239oPqKRUgkJpaQWi0LRELKIESAgBAmkS\nCITYJLHBseN9ttsPHmbuOWbejGfubPj8JCvv/96b966dM/eed+6555ExBopSLL5KN0D5dKCGpDhB\nDUlxghqS4gQ1JMUJakiKE9SQFCeoISlOKMqQiGgTEe0noreJ6FZXjVJqDyo0sk1EfgAHAGwAMABg\nJ4DrjDFvZftMW1ubWb1mVUH3AwC7qUQFXwYAkDAJpsej40wPjn7EtN/Pv3ORcDhzTDQmluTXPjk5\nzXRTpJ7pVU3dTPsW+MvJ/8Ji/zY2u1959UNjTHuu8wJF3ONcAG8bYw4BABE9BOByAFkNafWaVfjv\nS88XfEPb6KnIv9Z4bIzpZwa3M33nY/czvaSlkenzPrM6vR0JhtixoxPcKJ96+Q2mL+0/nenfr/8l\n0yEfv14uZGdQ7N/Gpj4QOZzPecUMbd0Ajlh6ILWPQUTfI6JdRLRrePjDIm6nVDMld7aNMfcYY/qN\nMf3t7W2lvp1SIYoZ2gYB9Fh6ZWqfMxbSZU/ETjJ918u/Zvpvz+1keiYaYzpSX8d0VBw/8MIBpneO\nvpi1LQjx7yedsoTpZ3fvY7r3hS1Mty1tZvqKc89k+pb+nzDdEODDbiUopkfaCaCPiHqJKATgWgCP\nuWmWUmsU3CMZY+JEdBOAbQD8ALYaY9501jKlpihmaIMx5gkATzhqi1LDFBxHKoRz+s82C3n89/KR\nhqePsmPrfn4N050dy5gO1/FH6mDQz7Tfz3UoHGR6RQv3W0amMrGheTGmIP/sdDzO9PDwKNPxOI87\nxYR/Nhvln29oCDN992XfZnpjz9fhivpA5BVjTH+u83SKRHGCGpLiBDUkxQlFOdulxitu9I1HbmO6\nazn3iZYu4z5NLMb9DHntQID7SNI/s30iAGgIZfwg6RNNCZ9oQsy1Sf9M3rtO+HORZJLpqPCZfvqP\ne5m++Mb16e2wn8fHSoX2SIoT1JAUJ6ghKU6oah9JMhY9kd4+doznCzU3R5iWc2XSD5mamuV6cobp\npPBLfD7+nfNZsSMZR5qdiTI9Ia4tzw8GZExLxKUaef6S9KE+Ej7Yk+8/nt6+ovcqlAPtkRQnqCEp\nTqipoc3Oavzg+Ag7FhBTHLNiaJsQj+9Bcb5MK5FDmQwH2EOfDCUkEnxYTIrP+n38fDlLJYc2fMin\nVDpaW5iW4YA/vJbJ9tShTakp1JAUJ6ghKU6oKR/p1eHd6e2EWPIzeJyHA+TjezLJHZF68Qjd3cnz\nydf18nUMZ63oYXpJOJPe2hhsYMeaQzz1NeTn95qO83DAs0deZfr+bTzVpqGOp42MjPFVKuMT3P+T\nUzLlQHskxQlqSIoT1JAUJ1R1qq0Xo1EeR7pn71amtx/iy4f+uPlOprsiC1s6Hk3wKZVYMvqJ2wAw\nnZhieibBfaJIgE/ndNR3ed579V0bmR4aFMvJI9wHa21pSm8f/tm/Pa+dC021VcqKGpLiBDUkxQk1\nFUe66elMCSa/mAu7dt0mpi9eeT7T42JJd8stFzEtfcWWJu7HtLbyZdd2dZJgkP8Z5dybvPbJsQmm\n39j3LtN9Iob10s3c/6sP8LhVJNDEdMDHU3/LgfZIihPUkBQnqCEpTqipONKu4R3p7T/ve5wde2+M\nV2B78qmXmf7xNZuZvrKP65FZHpfaM8RLz5yY4T6WXZ5vNsHn/WbEcqQGsVxJlgq8sPtsppeEuT92\n94t/8bxedxP3kbb+89n09uAv/sWORRZYAkfjSEpZyWlIRLSViIaIaK+1bxkR/YeIDqb+XVraZirV\nTj490n0ANol9twLYbozpA7A9pZVFTF4+EhGtAfC4MeaMlN4P4BJjzFEi6gTwjDHm1FzXKdZHsuec\nZOymq4vnE02KJUDHhrgPNLLjfe+bifJ9qBcht4B1XK4sD4rPxsXfeJb7UDjJ88XRzpcffe6CzzK9\nfAVfnn7TObx04Fg04899s+96FEOpfaTlxpiPCxQdA7C8wOsonxKKdrbNXJeWtVvT8siLg0IN6Xhq\nSEPq36FsJ2p55MVBoXNtjwH4FoBfpf591FmLPPjupkvT23/dwcsd73zlf0xftpHPtf3g4g1MH/7a\nB0yf3raW6ViS+zGzcbFOLjppncvjSJKQn/+Zm8M8lhMWOd0j0zwm9toQL75//2/4n/vI4eNMv7Mt\n8/KF8x4+lx1b25zTlS2IfB7/HwSwA8CpRDRARDdgzoA2ENFBAF9NaWURk7NHMsZcl+XQ+iz7lUWI\nRrYVJ9RUPtJz7x1Kb9fV87Venctbmb5yHfeRHnrrBaZff/MQ00R8bk6u35f4rPX7ufKPpJbXlnUG\nVog40R3rr2b6ifP5Orje3k6mu7/Tkd7uiayRTS8J2iMpTlBDUpyghqQ4oaZ8pHcPZWI/8rULxwaG\nme5pXMl0Sx0vEyxLATY18TxoWStAnp+wcpCkj5PLZ5qe4vOAATFvKF8x0Rjk+eMnx/m6uYFB/ruP\njmZywk/GTrBjbf4VKAXaIylOUENSnFBTQ5tdqkaWpWFpHQCaQ7zy/+iMqCwrhqN55fqE9ir95/N5\nP+7LoU8OmzFRuk+2paO+A16MjPA04Jg17B6d4lNBbXU6tClVjBqS4gQ1JMUJNeYjZXwLWXIYouRw\nS4ivR5iY4WVpfOJ8WSpwXvqswH7Ez/W4L9+GFJ3l58dEKEO2pb2eJ6BK/1C+/TJufd5Ouy0l2iMp\nTlBDUpyghqQ4oaZ8JBsZayE/9zuWhnlaycw095FyIl0w4VPF45n7S5/GJGXMSbxCwi+nW7xTVoKi\nTI1XTAsAAlbcKiFShkuF9kiKE9SQFCeoISlOqCkfyeut2zKs1CDKt+R6y3au12rJNBLb75kXRyLv\nZfB+ca2A9LHEvWVp5qVLeBmb2VlentlmKl6e10loj6Q4QQ1JcYIakuKEmvKRimFGvPk6l0+UKxZk\nM991k/6XnNfjZwdDPE6UkKm5Ce7nnNLH04j3vHaQ6bBVGtBkr+/hFO2RFCeoISlOUENSnFBTPlKz\ntWRo3us2E96+wLSYawsLv8RH4juV4ytmx45kDCvXEm0Zd5L5SvPm0gz//JnLeX7Srjgv6VMXyuQr\n6VybUlPkUx+ph4ieJqK3iOhNIvphar+WSFbS5NMjxQHcbIw5DcD5AG4kotOgJZIVi3wKbR0FcDS1\nPU5E+wB0A7gcwCWp0/4E4BkAt7hsXFyO75ZrIeM6Tc18ybVEzrWFgt6/uvRj5Of9/sx3MFeFabm8\n3P4skHvJd9zwe3+ho4/paGx71utHk6L0colYkI+Uqrd9FoCXoCWSFYu8DYmIGgE8AuBHxhi2NMGr\nRLKWR14c5GVIRBTEnBE9YIz5e2p3XiWStTzy4iCnj0RzA/a9APYZY35rHSp5iWQ5hWX7DnHxKquV\nXe2e18oVy5HzYRJj5No1e1uu9ZfXlrlMsi38XgHhM03Expk+Y9npTEsfzP7dZAyqVOQTkLwQwPUA\n3iCiPal9t2POgB5OlUs+DODqLJ9XFgH5PLU9j+zrTrVEsgJAI9uKI2pqrs0e+2XOTneXtyM/3y8R\nsZqY9/r7+SWN888flz6QXNc2bbLnXAPAiRlevu+MZZ9nWvpBts+m+UhKTaGGpDhBDUlxQs36SNKH\nOXOFd23EcJjXFGptb2F6aSN//ad8NZYkyNbXi/qT4tz5+UVcT8b4fNisyC+XNY5aRF2DeaWirLbF\nEpqPpNQQakiKE6p6aJMPrl5vBG+tW+J5LbmsOSr0hEh3HfmITzDLJdu2zvWm8vllaGQKDK/sL9OI\nD40dYTroE6WhZ/jwZU8fTccXWM6nQLRHUpyghqQ4QQ1JcUJV+0hJ8SAdCmWaGxTTDMkcUwHf38Ln\nl4eneGrG6maehhLr5VMmQZEKws4Vb9mW0xJGTGH4iF9Lhho6GrnP9JWei7Lee65x/Hr2FEzCeL8B\n3BXaIylOUENSnKCGpDihqn2kWJLHeuz4i0wjOT7JUy0kt/fX0LK7Ly7wfJGmYsethiZHim9PHmiP\npDhBDUlxghqS4oSq9pEiosTxWWtXpbd7u/nrObf0ftnzWrnmw7xKL1c7N161kendA5nXj1666ktl\naYP2SIoT1JAUJ6ghKU6gXL6D05sRDWNuVW4bgGqtKFGtbatUu1YbY7zXw6PMhpS+KdEuY0x/2W+c\nB9Xatmpt18fo0KY4QQ1JcUKlDOmeCt03H6q1bdXaLgAV8pGUTx86tClOKKshEdEmItpPRG8TUUXz\nOohoKxENEdFea19V1A6vxdrmZTMkIvID+B2AzQBOA3Bdql53pbgPwCaxr1pqh9debXNjTFl+AFwA\nYJulbwNwW7nun6VNawDstfR+AJ2p7U4A+yvZPqtdjwLYUK3tM8aUdWjrBmAvGR1I7asmqq52eK3U\nNldnOwtm7mtf0UfaQmubV4JyGtIggB5Lr0ztqybyqh1eDoqpbV4JymlIOwH0EVEvEYUAXIu5Wt3V\nxMe1w4ES1Q7PhzxqmwMVbN8nUmancQuAAwDeAXBHhR3YBzH3sp4Y5vy1GwC0Yu5p6CCApwAsq1Db\nLsLcsPU6gD2pny3V0r5P+tHItuIEdbYVJ6ghKU5QQ1KcoIakOEENSXGCGpLiBDUkxQlqSIoT/g8G\nFZk4YlQqhgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXFrnvh_yrDU",
        "colab_type": "text"
      },
      "source": [
        "## Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG6b1kedxAeR",
        "colab_type": "text"
      },
      "source": [
        "*The above was an image of Ankle Boot and thus labled as 9*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3Kw2S4X0NXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "NUM_CLASSES = 10\n",
        "EPOCHS = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6iZKEeKutr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OVMxrexz0yW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9bPtBS4z3lV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9Wvr6j90aIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkrDKFe70xxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4YuW_KL03dd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "167916a9-c402-4d8d-8583-52155321cad7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 24, 24, 32)        18464     \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                184330    \n",
            "=================================================================\n",
            "Total params: 203,434\n",
            "Trainable params: 203,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUDJ_UJn048_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "11e01b69-f298-4135-8396-c2bea79ad250"
      },
      "source": [
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=EPOCHS, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.4579 - acc: 0.8379 - val_loss: 0.3725 - val_acc: 0.8701\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.3111 - acc: 0.8901 - val_loss: 0.3195 - val_acc: 0.8843\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.2677 - acc: 0.9027 - val_loss: 0.3073 - val_acc: 0.8904\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.2347 - acc: 0.9165 - val_loss: 0.2747 - val_acc: 0.9019\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.2075 - acc: 0.9250 - val_loss: 0.2647 - val_acc: 0.9057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2bbc59b5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU9_bQov1osM",
        "colab_type": "text"
      },
      "source": [
        "## Analyzing our results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSm8ACEc1LB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = model.predict(x_test)\n",
        "predictions = []\n",
        "actual = []\n",
        "for i, j in zip(res, y_test):\n",
        "  predictions.append(i.argmax())\n",
        "  actual.append(j.argmax())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGkz_C181t1p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "bbfa6895-7e48-405e-807e-8e7c7d972bd2"
      },
      "source": [
        "print(classification_report(predictions, actual))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       972\n",
            "           1       0.99      0.98      0.98      1008\n",
            "           2       0.85      0.84      0.85      1013\n",
            "           3       0.93      0.88      0.90      1056\n",
            "           4       0.79      0.89      0.84       885\n",
            "           5       0.99      0.96      0.97      1033\n",
            "           6       0.76      0.73      0.75      1043\n",
            "           7       0.95      0.97      0.96       978\n",
            "           8       0.98      0.97      0.98      1016\n",
            "           9       0.96      0.97      0.97       996\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk19LMeI4J11",
        "colab_type": "text"
      },
      "source": [
        "**As we can clearly see, the results are improved compared to our previous model in which we used ANN instead of CNN**<br>\n",
        "*The file is in the same directory named FashionMnistANN*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBCD0lxl2d2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}